{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "plt.style.use('seaborn-bright')\n",
    "# print(plt.style.available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_processed_2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Test Data into Train and CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1].astype(int)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainx,cvx, trainy,cvy = train_test_split(x,y, test_size=0.1, random_state=42, stratify=y)\n",
    "\n",
    "# After we randomly split the dataset, we've the following class proportions in percent: \n",
    "print('All:', np.bincount(y) / len(y) * 100.0)\n",
    "print('Training:', np.bincount(trainy) / len(trainy) * 100.0)\n",
    "print('Test:', np.bincount(cvy) / len(cvy) * 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(trainx,trainy)\n",
    "print('Classification Score on trainx/y :', clf.score(trainx, trainy)) # Perfect score  1\n",
    "print('Classification Score on trainx/y :', clf.score(cvx, cvy)) # Perfect score  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "# Get just the probability of class in 0th-column and that implies getting the probability of \"Not Renewing the Policy\"\n",
    "# trainy_prob = clf.predict_proba(trainx)[:,0] # Get just the probability of No-renewal (class in 0th-column)\n",
    "# fpr, tpr, thresholds = roc_curve(trainy, trainy_prob, pos_label=1)\n",
    "# roc_auc = auc(1-fpr, 1-tpr) # Because we want the P(renewing the policy) when we know the P(NOT renewing the policy)\n",
    "\n",
    "# cvy_prob = clf.predict_proba(cvx)[:,0] # Get just the probability of class in first-column\n",
    "# fpr_cv, tpr_cv, threshold_cv = roc_curve(cvy, cvy_prob, pos_label=1)\n",
    "# roc_auc_cv = auc(1-fpr_cv, 1-tpr_cv)\n",
    "\n",
    "\n",
    "# Get just the probability of class in 1st-column and that implies getting the probability of \"Renewing the Policy\"\n",
    "trainy_prob = clf.predict_proba(trainx)[:,1] # Get just the probability of Renewal (class in 1st-column)\n",
    "fpr, tpr, thresholds = roc_curve(trainy, trainy_prob, pos_label=1)\n",
    "roc_auc = auc(fpr, tpr) # Because we want the P(renewing the policy)\n",
    "\n",
    "cvy_prob = clf.predict_proba(cvx)[:,1] # Get just the probability of class in 1st-column, P()\n",
    "fpr_cv, tpr_cv, threshold_cv = roc_curve(cvy, cvy_prob, pos_label=1)\n",
    "roc_auc_cv = auc(fpr_cv, tpr_cv)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(fpr, tpr, color='darkorange', alpha=0.5, lw=2, linestyle='-', label='Training ROC Curve (area = {0:.2f})'.format(roc_auc))\n",
    "plt.plot(fpr_cv, tpr_cv, color='deeppink', alpha=0.5, lw=2, linestyle='-', label='Testing ROC Curve (area = {0:.2f})'.format(roc_auc_cv))\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to calculate the AUC, you need to have probabilities.\n",
    "roc_auc_score(trainy, trainy_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Pre-processing of TEST dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test.csv')\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.rename(columns={'Income':'income',\n",
    "                   'Count_3-6_months_late':'count_3-6_months_late', \n",
    "                   'Count_6-12_months_late':'count_6-12_months_late',\n",
    "                   'Count_more_than_12_months_late':'count_more_than_12_months_late'\n",
    "                  })\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df.drop(columns=['id'],axis=1,inplace=True) # Don't because it is requirerd for final submimssion\n",
    "# test_df.head()\n",
    "iddf = test_df['id']\n",
    "print(iddf.shape)\n",
    "test_df = test_df.iloc[:,1:]\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['age_in_yrs'] = (test_df['age_in_days'] / 365).astype(int)\n",
    "test_df.drop(columns=['age_in_days'],axis=1, inplace=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.isnull().sum())\n",
    "tmp = test_df[['count_3-6_months_late', 'count_6-12_months_late', 'count_more_than_12_months_late']].fillna(0)\n",
    "test_df.update(tmp)\n",
    "print(test_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df.update( test_df['application_underwriting_score'].fillna(99.89) ) # Filling with mode value of test set\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Pre-processing of TEST dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['income'] = test_df['income'].apply(np.log).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "data_scalar = preprocessing.MinMaxScaler()\n",
    "\n",
    "test_df['age_in_yrs'] = data_scalar.fit_transform(test_df[['age_in_yrs']]).flatten().round(3)\n",
    "test_df['application_underwriting_score'] = data_scalar.fit_transform(test_df[['application_underwriting_score']]).flatten().round(3)\n",
    "test_df['no_of_premiums_paid'] = data_scalar.fit_transform(test_df[['no_of_premiums_paid']]).flatten().round(2)\n",
    "test_df['premium'] = test_df['premium'].apply(np.log).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing  utility function categorize from util.py defined in this directory of project\n",
    "from util import categorize\n",
    "\n",
    "tmp_df = categorize(test_df[['sourcing_channel']])\n",
    "test_df = test_df.join(tmp_df)\n",
    "\n",
    "tmp_df = categorize(test_df[['residence_area_type']])\n",
    "test_df = test_df.join(tmp_df)\n",
    "\n",
    "test_df.drop(['sourcing_channel', 'residence_area_type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[['age_in_yrs', \n",
    "               'income', \n",
    "               'application_underwriting_score', \n",
    "               'premium',\n",
    "               'perc_premium_paid_by_cash_credit', \n",
    "               'no_of_premiums_paid',\n",
    "               'count_3-6_months_late', 'count_6-12_months_late', 'count_more_than_12_months_late', \n",
    "               'sourcing_channel_A', 'sourcing_channel_B', 'sourcing_channel_C', 'sourcing_channel_D', 'sourcing_channel_E', \n",
    "               'residence_area_type_Rural', 'residence_area_type_Urban',\n",
    "               ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testx = test_df.iloc[:,:-1]\n",
    "# testy = test_df.iloc[:,-1].astype(int)\n",
    "# print(testx.shape)\n",
    "# print(testy.shape)\n",
    "testx = test_df\n",
    "print(testx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Following pre-procecssing activities are done as part of this deliverable/notebook:\n",
    "1. Preprocess by applying np.log on the following columns:\n",
    "    1.1 income\n",
    "    1.2 premium\n",
    "2. Pre-process with MinMaxScalara() the following columns: \n",
    "    2.1 age_in_yrs, \n",
    "    2.2 application_underwriting_score\n",
    "    2.3 no_of_premiums_paid\n",
    "3. Pre-process Feature Categories with LabelEncoder and OneHotEncoder on the following columns: \n",
    "    3.1 sourcing_channel, \n",
    "    3.2 residence_area_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A\n",
    "\n",
    "The base probability of receiving a premium on a policy without considering any incentive.\n",
    "\n",
    "The probabilities predicted by the participants would be evaluated using AUC ROC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testy_prob = clf.predict_proba(testx)[:,1] # Get just the probability of renewal (class in 1st-column)\n",
    "# fpr_test, tpr_test, threshold_test = roc_curve(??, testy_prob, pos_label=1)\n",
    "# roc_auc_test = auc(fpr_test, tpr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy = clf.predict(testx)\n",
    "testy_prob = pd.DataFrame(testy_prob)[1].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = pd.concat([iddf.to_frame(), testy_prob],\n",
    "                    axis=1)\n",
    "finaldf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part  B\n",
    "\n",
    "The monthly incentives you will provide on each policy to maximize the net revenue based on the provided formulae in the problem statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
